#!/usr/bin/env python3
"""
Setup script for LocalRAG
Automated installation and configuration
"""

import os
import sys
import subprocess
import platform
from pathlib import Path

def run_command(cmd, description):
    """Execute a shell command with error handling"""
    print(f"üîÑ {description}...")
    try:
        result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
        print(f"‚úÖ {description}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå {description} - Erreur: {e.stderr}")
        return False

def detect_system():
    """Detect system and GPU capabilities"""
    system = platform.system()
    print(f"üñ•Ô∏è  Syst√®me d√©tect√©: {system}")
    
    gpu_info = {}
    
    # Check for Mac M1/M2/M3
    if system == "Darwin":
        try:
            import torch
            if torch.backends.mps.is_available():
                gpu_info["type"] = "MPS"
                gpu_info["available"] = True
                print("‚úÖ Mac avec puce Apple Silicon (MPS disponible)")
            else:
                gpu_info["type"] = "None"
                gpu_info["available"] = False
                print("‚ö†Ô∏è Mac sans support MPS")
        except ImportError:
            print("‚ö†Ô∏è PyTorch non install√© - impossible de v√©rifier MPS")
            gpu_info["type"] = "Unknown"
            gpu_info["available"] = False
    
    # Check for NVIDIA CUDA
    elif system in ["Linux", "Windows"]:
        try:
            result = subprocess.run("nvidia-smi", capture_output=True, text=True)
            if result.returncode == 0:
                gpu_info["type"] = "CUDA"
                gpu_info["available"] = True
                print("‚úÖ GPU NVIDIA d√©tect√© (CUDA disponible)")
            else:
                gpu_info["type"] = "None"
                gpu_info["available"] = False
                print("‚ö†Ô∏è Aucun GPU NVIDIA d√©tect√©")
        except FileNotFoundError:
            gpu_info["type"] = "None"
            gpu_info["available"] = False
            print("‚ö†Ô∏è NVIDIA drivers non install√©s")
    
    return system, gpu_info

def install_python_packages(system_type, gpu_info):
    """Install Python packages with system-specific optimizations"""
    print("\nüì¶ Installation des packages Python...")
    
    # Base installation
    if not run_command("pip install --upgrade pip", "Mise √† jour pip"):
        return False
    
    # Install PyTorch with appropriate backend
    if gpu_info["type"] == "CUDA":
        torch_cmd = "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
        if not run_command(torch_cmd, "Installation PyTorch (CUDA)"):
            return False
    elif gpu_info["type"] == "MPS":
        if not run_command("pip install torch torchvision torchaudio", "Installation PyTorch (MPS)"):
            return False
    else:
        print("‚ö†Ô∏è Installation PyTorch CPU (performance limit√©e)")
        if not run_command("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu", "Installation PyTorch (CPU)"):
            return False
    
    # Install other requirements
    if not run_command("pip install -r requirements.txt", "Installation d√©pendances"):
        return False
    
    return True

def setup_ollama():
    """Setup Ollama for image analysis"""
    print("\nü¶ô Configuration Ollama...")
    
    # Check if ollama is installed
    try:
        result = subprocess.run("ollama --version", capture_output=True, text=True, shell=True)
        if result.returncode == 0:
            print("‚úÖ Ollama d√©j√† install√©")
        else:
            print("‚ùå Ollama non trouv√©")
            return False
    except FileNotFoundError:
        print("‚ùå Ollama non install√©")
        print("üìã Installation manuelle requise:")
        print("   macOS: brew install ollama")
        print("   Linux: curl -fsSL https://ollama.ai/install.sh | sh")
        print("   Windows: T√©l√©charger depuis https://ollama.ai")
        return False
    
    # Start ollama service
    if not run_command("ollama serve &", "D√©marrage service Ollama"):
        print("‚ö†Ô∏è Le service Ollama doit √™tre d√©marr√© manuellement")
    
    # Pull required model
    if run_command("ollama pull llava", "T√©l√©chargement mod√®le llava"):
        print("‚úÖ Mod√®le llava install√© pour l'analyse d'images")
    else:
        print("‚ö†Ô∏è √âchec t√©l√©chargement llava - l'analyse d'images sera limit√©e")
    
    return True

def create_config():
    """Create default configuration"""
    print("\n‚öôÔ∏è Cr√©ation configuration par d√©faut...")
    
    config_path = Path("config.py")
    if config_path.exists():
        print("‚úÖ config.py existe d√©j√†")
        return True
    
    try:
        import shutil
        shutil.copy("config_example.py", "config.py")
        print("‚úÖ config.py cr√©√© depuis config_example.py")
        print("üìù √âditez config.py pour personnaliser les param√®tres")
        return True
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation config.py: {e}")
        return False

def main():
    """Main setup process"""
    print("üöÄ LocalRAG - Installation automatique")
    print("=" * 50)
    
    # System detection
    system, gpu_info = detect_system()
    
    if not gpu_info["available"]:
        print("\n‚ö†Ô∏è ATTENTION: Aucun GPU d√©tect√©")
        print("Le syst√®me fonctionnera en mode CPU avec des performances limit√©es")
        response = input("Continuer quand m√™me ? (y/N): ")
        if response.lower() != 'y':
            print("Installation annul√©e")
            sys.exit(1)
    
    # Installation steps
    steps = [
        ("Python packages", lambda: install_python_packages(system, gpu_info)),
        ("Ollama setup", setup_ollama),
        ("Configuration", create_config)
    ]
    
    success_count = 0
    for step_name, step_func in steps:
        print(f"\nüìã √âtape: {step_name}")
        if step_func():
            success_count += 1
        else:
            print(f"‚ùå √âchec √©tape: {step_name}")
    
    print("\n" + "=" * 50)
    
    if success_count == len(steps):
        print("üéâ Installation termin√©e avec succ√®s !")
        print("\nüìã Prochaines √©tapes:")
        print("1. python validate_environment.py  # Valider l'installation")
        print("2. √âditer config.py selon vos besoins")
        print("3. python step01_indexer.py /path/to/docs  # Commencer l'indexation")
    else:
        print(f"‚ö†Ô∏è Installation partiellement r√©ussie ({success_count}/{len(steps)} √©tapes)")
        print("V√©rifiez les erreurs ci-dessus et relancez si n√©cessaire")

if __name__ == "__main__":
    main()