# üîç LocalRAG - Syst√®me RAG Local Complet

## Vue d'ensemble

LocalRAG est un syst√®me de **Retrieval-Augmented Generation (RAG)** enti√®rement local, con√ßu pour indexer et interroger efficacement de la documentation technique. Le syst√®me fonctionne en plusieurs √©tapes orchestr√©es pour offrir une recherche s√©mantique haute performance sans d√©pendance cloud.

## üèóÔ∏è Architecture du processus

```mermaid
graph TD
    A[üìÇ Documentation Source] --> B[Step 01: Indexation]
    B --> C[üìä Index Vectoriel FAISS]
    C --> D[Step 02: Recherche - √Ä venir]
    D --> E[Step 03: G√©n√©ration - √Ä venir]
    E --> F[üéØ R√©ponse Contextualis√©e]
```

## üìã √âtapes du processus

### ‚úÖ **Step 01 - Indexation** (`step01_indexer.py`)
**Statut**: ‚úÖ Impl√©ment√© et optimis√©

Transform la documentation brute en index vectoriel searchable.

### ‚úÖ **Step 02 - Upload Embeddings** (`step02_upload_embeddings.py`)  
**Statut**: ‚úÖ Impl√©ment√© et test√©

Convertit l'index FAISS en SafeTensors et l'upload vers Hugging Face Hub.

---

## üöÄ Step 01 - Indexation Vectorielle

### üéØ **Objectif**
Convertir la documentation technique (HTML/Markdown) en repr√©sentations vectorielles pour permettre une recherche s√©mantique ultra-rapide.

### üìä **Pipeline de traitement**

```mermaid
graph LR
    A[üìÅ Documents] --> B[üîç Parsing]
    B --> C[‚úÇÔ∏è Chunking]
    C --> D[üñºÔ∏è Analyse Images]
    D --> E[üß† Embeddings]
    E --> F[‚ö° FAISS Index]
```

#### 1. **D√©couverte et Parsing** 
- Scan r√©cursif des r√©pertoires
- Support multi-format : `.html`, `.htm`, `.md`, `.markdown`
- Parser unifi√© avec gestion d'erreurs robuste
- Extraction du contenu, titres, sections, images et liens

#### 2. **Segmentation Intelligente**
- D√©coupage en chunks s√©mantiquement coh√©rents
- Pr√©servation du contexte (titre, section parent)
- Optimisation de la taille pour les mod√®les d'embedding

#### 3. **Analyse Multimodale**
- **Images** : Analyse automatique avec Ollama (descriptions contextuelles)
- **Liens** : Extraction et catalogage des r√©f√©rences
- **M√©tadonn√©es** : Enrichissement avec informations structurelles

#### 4. **G√©n√©ration d'Embeddings**
- **Mod√®le principal** : `Qwen3-Embedding-4B` (2560 dimensions)
- **Fallback** : `paraphrase-multilingual-MiniLM-L12-v2`
- **Optimisations GPU** : Support MPS (Mac) et CUDA
- **Traitement par batch** adaptatif selon la puissance GPU

#### 5. **Indexation Vectorielle**
- **Backend** : FAISS-HNSW (Facebook AI Similarity Search)
- **Performance** : 10x plus rapide que ChromaDB
- **Persistance** : Sauvegarde automatique sur disque
- **Scalabilit√©** : Gestion de millions de vecteurs

### üõ†Ô∏è **Utilisation**

#### Installation des d√©pendances
```bash
pip install -r requirements.txt
```

#### Indexation compl√®te
```bash
python step01_indexer.py /path/to/documentation
```

#### Indexation incr√©mentale (nouveaux fichiers uniquement)
```bash
python step01_indexer.py /path/to/documentation --incremental
```

#### Test sur un fichier unique
```bash
python step01_indexer.py /path/to/documentation --single-file document.html
```

### ‚öôÔ∏è **Options de configuration**

| Option | Description | Recommand√© pour |
|--------|-------------|-----------------|
| `--db-path` | Chemin de l'index FAISS | Personnaliser le stockage |
| `--debug` | Mode debug d√©taill√© | D√©veloppement/Debug |
| `--incremental` | Indexation incr√©mentale | Mises √† jour r√©guli√®res |
| `--no-flash-attention` | D√©sactive Flash Attention 2 | Mac avec erreurs GPU |
| `--no-reranker` | D√©sactive le reranker | GPU limit√© |

### üìà **Performances**

#### Environnements support√©s
- **üçé Mac M1/M2/M3** : MPS (Metal Performance Shaders)
- **üöÄ Linux/Windows** : CUDA (NVIDIA GPU)
- **‚ùå CPU** : Non support√© (performance insuffisante)

#### M√©triques typiques
- **Parsing** : ~100 fichiers HTML/min
- **Embeddings** : ~50 documents/sec (MPS) | ~200 documents/sec (CUDA)
- **Indexation FAISS** : ~1000 vecteurs/sec
- **M√©moire** : ~2GB RAM pour 100k chunks

### üóÉÔ∏è **Structure des donn√©es**

#### Index FAISS
```
faiss_index/
‚îú‚îÄ‚îÄ index.faiss          # Index vectoriel HNSW
‚îú‚îÄ‚îÄ metadata.json        # M√©tadonn√©es enrichies
‚îú‚îÄ‚îÄ mappings.pkl         # Mapping ID ‚Üî Index
‚îî‚îÄ‚îÄ tracking.json        # √âtat d'indexation
```

#### M√©tadonn√©es par chunk
```json
{
  "source_file": "/path/to/document.html",
  "title": "Guide d'utilisation",
  "heading": "Configuration avanc√©e",
  "content_length": 1247,
  "images_count": 3,
  "links_count": 5,
  "indexed_at": "2024-01-15T14:30:00",
  "chunk_content": "Contenu du segment..."
}
```

### üîß **Architecture technique**

#### Classes principales
- **`TechnicalDocIndexer`** : Orchestrateur principal
- **`UniversalDocumentParser`** : Parser unifi√© HTML/Markdown
- **`VectorIndexer`** : Gestionnaire d'embeddings et FAISS
- **`OllamaImageAnalyzer`** : Analyse multimodale des images
- **`Qwen3Reranker`** : Reranking s√©mantique (step 02)

#### Flux de donn√©es
1. **Fichiers** ‚Üí **Chunks** (Parser)
2. **Chunks** ‚Üí **Embeddings** (Qwen3)
3. **Embeddings** ‚Üí **Index FAISS** (VectorIndexer)
4. **M√©tadonn√©es** ‚Üí **JSON** (Tracking)

### ‚ö° **Optimisations**

#### Gestion m√©moire
- **Nettoyage automatique** : Cache MPS vid√© apr√®s chaque batch
- **Batch adaptatif** : Taille ajust√©e selon GPU et longueur documents
- **Streaming** : Traitement par petits lots pour √©viter l'OOM

#### Performance GPU
- **Pas de fallback CPU** : √âchec imm√©diat si GPU indisponible
- **Flash Attention 2** : Acc√©l√©ration des transformers (CUDA)
- **Precision mixte** : FP16 automatique sur GPU compatibles

### üö® **Gestion d'erreurs**

#### Robustesse
- **Collecteur d'erreurs** : Catalogage centralis√© des √©checs
- **Continuation** : Traitement des autres fichiers si un √©choue
- **Rapport d√©taill√©** : Statistiques compl√®tes en fin d'ex√©cution

#### Types d'erreurs g√©r√©es
- Images manquantes ou corrompues
- HTML malform√©
- Timeouts GPU
- Erreurs d'encoding

---

## üìÖ **Roadmap**

### üîÑ **Step 02 - Recherche** (√Ä impl√©menter)
- Interface de recherche s√©mantique
- Reranking avec Qwen3-Reranker-4B
- Syst√®me de scoring hybride
- Cache de requ√™tes fr√©quentes

### ü§ñ **Step 03 - G√©n√©ration** (√Ä impl√©menter)  
- Int√©gration LLM local (Ollama/MLX)
- G√©n√©ration de r√©ponses contextualis√©es
- Templates de prompts optimis√©s
- Streaming des r√©ponses

### üîß **Step 04 - Interface** (√Ä impl√©menter)
- API REST/FastAPI
- Interface web interactive
- Chat en temps r√©el
- Visualisation des r√©sultats

---

## üõ°Ô∏è **S√©curit√© et confidentialit√©**

- **100% Local** : Aucune donn√©e envoy√©e vers des services externes
- **Chiffrement** : Index FAISS peut √™tre chiffr√© au repos
- **Isolation** : Traitement en sandbox local
- **Contr√¥le total** : Vos donn√©es restent sur votre infrastructure

---

## ü§ù **Contribution**

Le projet suit une architecture modulaire permettant des contributions cibl√©es :
- **Step 01** : Optimisations d'indexation
- **Step 02+** : Nouvelles √©tapes du pipeline
- **Parsers** : Support de nouveaux formats
- **Backends** : Int√©gration d'autres bases vectorielles

---

## üìä **Statistiques d'utilisation**

Apr√®s indexation, le script affiche :
- Nombre de fichiers trait√©s
- Chunks g√©n√©r√©s et index√©s
- Images analys√©es
- Erreurs rencontr√©es
- Temps de traitement total
- Taille de l'index final

**Exemple** :
```
‚úÖ Indexation termin√©e !
üìä Statistiques finales :
   - Fichiers trait√©s : 1,247
   - Chunks g√©n√©r√©s : 12,458  
   - Images analys√©es : 3,891
   - Vecteurs index√©s : 12,458
   - Erreurs : 23 (1.8%)
   - Dur√©e totale : 4min 32s
   - Index FAISS : 2.1 GB
```

---

## üåê Step 02 - Upload Embeddings vers Hugging Face

### üéØ **Objectif**
Convertir l'index FAISS local en format SafeTensors et l'upload vers Hugging Face Hub pour partage et r√©utilisation.

### üìä **Pipeline de conversion**

```mermaid
graph LR
    A[üìÇ Index FAISS] --> B[üîÑ Conversion SafeTensors]
    B --> C[üìã M√©tadonn√©es JSON]
    C --> D[üìù README Auto]
    D --> E[üöÄ Upload HF Hub]
```

#### 1. **Conversion Format**
- **FAISS ‚Üí SafeTensors** : Format s√©curis√© pr√©f√©r√© par HF
- **Extraction vecteurs** : Reconstruction depuis index HNSW
- **Pr√©servation mappings** : ID ‚Üî Index dans m√©tadonn√©es
- **Validation int√©grit√©** : V√©rification dimensions et coh√©rence

#### 2. **Upload S√©curis√©**
- **Token HF** : Authentification s√©curis√©e (saisie masqu√©e)
- **Repository priv√©/public** : Contr√¥le de visibilit√©
- **M√©tadonn√©es enrichies** : Documentation compl√®te auto-g√©n√©r√©e
- **README automatique** : Guide d'utilisation avec exemples de code

### üõ†Ô∏è **Utilisation**

#### Upload interactif (recommand√©)
```bash
python step02_upload_embeddings.py
```

#### Upload avec param√®tres
```bash
python step02_upload_embeddings.py --repo-name username/my-embeddings --private
```

#### Test de conversion uniquement
```bash
python step02_upload_embeddings.py --dry-run
```

### ‚öôÔ∏è **Options de configuration**

| Option | Description | Exemple |
|--------|-------------|---------|
| `faiss_index_path` | Chemin index FAISS | `./faiss_index` |
| `--token` | Token HF (ou interactif) | `hf_xxxxx` |
| `--repo-name` | Repository HF | `username/embeddings` |
| `--dataset-name` | Nom du dataset | `embeddings` |
| `--private` | Repository priv√© | Flag |
| `--dry-run` | Test sans upload | Flag |

### üìÅ **Structure upload√©e**

#### Fichiers g√©n√©r√©s sur HF Hub
```
dataset-repo/
‚îú‚îÄ‚îÄ embeddings.safetensors     # Vecteurs au format SafeTensors
‚îú‚îÄ‚îÄ embeddings_metadata.json  # M√©tadonn√©es + mappings ID
‚îî‚îÄ‚îÄ README.md                  # Documentation auto-g√©n√©r√©e
```

#### Contenu SafeTensors
```python
{
    'embeddings': torch.Tensor,  # Shape: [n_vectors, dimension]
}
```

#### M√©tadonn√©es JSON
```json
{
  "format_version": "1.0",
  "total_vectors": 12458,
  "vector_dimension": 2560,
  "faiss_index_type": "HNSW",
  "embedding_model": "Qwen/Qwen3-Embedding-4B",
  "conversion_timestamp": "2024-01-15T14:30:00",
  "ordered_ids": ["doc1#chunk1", "doc1#chunk2", ...],
  "id_to_idx": {"doc1#chunk1": 0, "doc1#chunk2": 1, ...}
}
```

### üîÑ **R√©utilisation des embeddings**

#### T√©l√©chargement depuis HF Hub
```python
from huggingface_hub import hf_hub_download
from safetensors.torch import load_file
import json

# T√©l√©charger les fichiers
embeddings_file = hf_hub_download(repo_id="username/repo", filename="embeddings.safetensors")
metadata_file = hf_hub_download(repo_id="username/repo", filename="embeddings_metadata.json")

# Charger les embeddings
tensors = load_file(embeddings_file)
embeddings = tensors['embeddings']  # torch.Tensor [n_vectors, dimension]

# Charger m√©tadonn√©es
with open(metadata_file, 'r') as f:
    metadata = json.load(f)
```

#### Recherche s√©mantique directe
```python
import torch.nn.functional as F

def search_embeddings(query_embedding, embeddings, metadata, top_k=10):
    """Recherche s√©mantique dans les embeddings upload√©s."""
    # Similarit√© cosinus
    similarities = F.cosine_similarity(query_embedding.unsqueeze(0), embeddings, dim=1)
    
    # Top-K r√©sultats
    top_scores, top_indices = torch.topk(similarities, top_k)
    
    # R√©cup√©ration des IDs originaux
    ordered_ids = metadata['ordered_ids']
    results = []
    for idx, score in zip(top_indices, top_scores):
        doc_id = ordered_ids[idx.item()]
        results.append({'id': doc_id, 'score': score.item()})
    
    return results
```

### üìà **Avantages SafeTensors**

#### vs. Format Pickle (.pkl)
- **‚úÖ S√©curit√©** : Pas d'ex√©cution de code arbitraire
- **‚úÖ Performance** : Chargement plus rapide
- **‚úÖ Interop√©rabilit√©** : Compatible tous frameworks ML
- **‚úÖ M√©tadonn√©es** : Format structur√© et extensible
- **‚úÖ Validation** : V√©rification int√©grit√© automatique

#### vs. Index FAISS natif
- **‚úÖ Portabilit√©** : Ind√©pendant de FAISS
- **‚úÖ Versioning** : Suivi des versions sur Git LFS
- **‚úÖ Partage** : Distribution facile via HF Hub
- **‚úÖ Documentation** : README et m√©tadonn√©es auto-g√©n√©r√©es

### üîí **S√©curit√© et confidentialit√©**

#### Gestion des tokens
- **Saisie masqu√©e** : Token jamais affich√© en clair
- **Pas de stockage** : Token utilis√© uniquement en m√©moire
- **HTTPS** : Communication chiffr√©e avec HF Hub

#### Contr√¥le d'acc√®s
- **Repository priv√©** : Accessible uniquement au propri√©taire
- **Repository public** : Disponible pour la communaut√©
- **Token permissions** : Respecte les droits du token fourni

### üéØ **Cas d'usage**

1. **Backup cloud** : Sauvegarde s√©curis√©e des embeddings
2. **Partage √©quipe** : Distribution des embeddings pr√©-calcul√©s
3. **R√©plication** : D√©ploiement sur diff√©rents environnements  
4. **Research** : Partage de datasets pour recherche
5. **Production** : Int√©gration dans pipelines ML

### ‚ö° **Performance**

#### M√©triques typiques
- **Conversion** : ~1M vecteurs/min (2560D)
- **Upload** : D√©pend de la bande passante
- **Taille typique** : ~10MB/1K vecteurs (2560D, float32)
- **Compression** : ~30% vs format FAISS original

#### Optimisations
- **Streaming upload** : Upload par chunks pour gros datasets
- **Compression automatique** : Git LFS pour fichiers volumineux
- **Validation** : Checksum avant upload