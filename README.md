---
title: Swift MLX documentation research
emoji: üîç
colorFrom: blue
colorTo: green
sdk: gradio
sdk_version: 5.43.1
app_file: step04_chatbot.py
pinned: false
license: mit
hardware: zerogpu
short_description: Search in the Swift MLX documentation
models:
- Qwen/Qwen3-Embedding-4B
- Qwen/Qwen3-Reranker-4B
- Qwen/Qwen3-4B-Instruct-2507
datasets:
- VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B
tags:
- rag
- retrieval-augmented-generation
- qwen3
- semantic-search
- question-answering
- zero-gpu
- mcp-server
- faiss
---

# üîç LocalRAG - Syst√®me RAG Complet avec Qwen3

‚úÖ **Syst√®me complet et fonctionnel** - Compatible MPS (Mac), CUDA et ZeroGPU Spaces

Syst√®me RAG (Retrieval-Augmented Generation) utilisant les mod√®les Qwen3 de derni√®re g√©n√©ration avec pipeline 2 √©tapes : recherche vectorielle + reranking + g√©n√©ration stream√©e.

## ‚ö° Fonctionnalit√©s

### üß† **Mod√®les IA Avanc√©s**
- **Embeddings**: Qwen3-Embedding-4B (2560 dimensions)
- **Reranking**: Qwen3-Reranker-4B pour l'affinage des r√©sultats
- **G√©n√©ration**: Qwen3-4B-Instruct-2507 avec streaming
- **Optimisation ZeroGPU**: Support natif avec d√©corateurs @spaces.GPU

### üìÑ **Support Multi-Formats avec PDF Intelligent**
- **HTML/Markdown**: Parsing structurel avec pr√©servation hi√©rarchique
- **PDF avanc√©**: Chunking s√©mantique intelligent pour documents longs (50+ pages)
- **D√©tection automatique**: Structure, TOC et titres des PDFs
- **Overlap contextuel**: Pr√©servation du contexte entre chunks (100-200 mots)
- **Batch processing**: Indexation par lots pour √©viter les crashes m√©moire

### üîç **Recherche S√©mantique Avanc√©e**
- **Pipeline 2 √©tapes**: Recherche vectorielle + reranking
- **Index FAISS**: Recherche haute performance sur de gros volumes
- **Scores d√©taill√©s**: Embedding + reranking pour chaque document
- **S√©lection intelligente**: Top-K adaptatif selon pertinence

### üöÄ **Modes de D√©ploiement Flexibles**
- **Mode HuggingFace Hub**: T√©l√©chargement automatique des embeddings
- **Mode FAISS Local**: Utilisation directe de l'index local (5x plus rapide)
- **Mode Offline**: Fonctionnement complet sans connexion internet
- **Mode Public S√©curis√©**: Partage via URL avec authentification admin

### üîê **S√©curit√© et Authentification**
- **Mot de passe al√©atoire**: 16 caract√®res cryptographiquement s√©curis√©s
- **G√©n√©ration automatique**: Combinaison lettres + chiffres + symboles
- **Session unique**: Nouveau mot de passe √† chaque d√©marrage
- **Contr√¥le d'acc√®s**: Interface publique avec protection admin

### üí¨ **G√©n√©ration Contextuelle**
- **Streaming**: R√©ponse progressive token par token
- **Contexte enrichi**: Int√©gration des documents les plus pertinents
- **R√©f√©rences**: Sources avec scores de pertinence
- **Qualit√©**: R√©ponses bas√©es uniquement sur le contexte fourni

### üîå **Int√©gration MCP**
- **Serveur MCP natif**: Fonction `ask_rag_question()` expos√©e
- **Param√®tres configurables**: Nombre documents, activation reranking
- **Compatible**: Claude Desktop, VS Code, Cursor IDE
- **API structur√©e**: R√©ponses JSON avec sources et m√©tadonn√©es

## üõ†Ô∏è Architecture & √âtapes

### Pipeline de Traitement
1. **Step01** : T√©l√©chargement automatique de documentation web (optionnel)
2. **Step02** : Indexation universelle (HTML/Markdown/PDF ‚Üí FAISS + m√©tadonn√©es)
3. **Step03** : Upload embeddings vers HuggingFace Hub (optionnel)
4. **Step04** : Interface de chat RAG (mode local ou cloud)

### Recherche en 2 √âtapes
1. **Recherche vectorielle** : FAISS IndexFlatIP (cosine similarity)
2. **Reranking** : Qwen3-Reranker-4B pour affiner la pertinence
3. **G√©n√©ration** : Qwen3-4B-Instruct-2507 avec streaming

## üì• Step01 - T√©l√©chargeur de Documentation

Le nouveau **step01_downloader.py** permet de t√©l√©charger automatiquement de la documentation depuis internet pour alimenter votre syst√®me RAG.

### Fonctionnalit√©s
- **Interface simplifi√©e** : Utilisation directe avec --start-url
- **URLs de d√©part multiples** : Support de plusieurs points d'entr√©e
- **T√©l√©chargement intelligent** : Respect des robots.txt et limitations
- **Formats support√©s** : HTML, Markdown, PDF
- **Filtrage automatique** : Exclusion des fichiers non pertinents
- **D√©tection automatique** : Base URL automatiquement d√©tect√©e

### Utilisation
```bash
# T√©l√©charger depuis une URL de d√©part (stock√© dans ./data/docs/)
python step01_downloader.py --start-url https://pytorch.org/docs/stable/ --output docs

# T√©l√©charger depuis plusieurs URLs de d√©part (stock√© dans ./data/api_docs/)
python step01_downloader.py --start-url https://site1.com/docs --start-url https://site2.com/api --output api_docs

# Options avanc√©es avec base URL personnalis√©e (stock√© dans ./data/swift_docs/)
python step01_downloader.py --start-url https://docs.swift.org/swift-book/ --base-url https://docs.swift.org --output swift_docs --workers 5

# Reprendre un t√©l√©chargement interrompu
python step01_downloader.py --start-url https://site.com/docs --output my_docs --resume
```

### Options disponibles
- `--start-url` : URL de d√©part pour le crawling (requis, peut √™tre r√©p√©t√©)
- `--base-url` : URL de base (optionnel, auto-d√©tect√© depuis la premi√®re start-url)
- `--output` : Nom du dossier (sera cr√©√© dans ./data/, d√©faut: downloaded_docs)
- `--workers` : Nombre de workers parall√®les (d√©faut: 3)
- `--resume` : Reprendre un t√©l√©chargement interrompu (flag optionnel)

## üöÄ Utilisation

### Installation & D√©marrage Rapide
```bash
# Cloner le projet
git clone [repo-url]
cd LocalRagModel

# Installer les d√©pendances (inclut Selenium pour t√©l√©chargement web)
pip install -r requirements.txt

# Option 1: T√©l√©charger documentation web (optionnel)
# Les donn√©es sont automatiquement stock√©es dans ./data/[nom_dossier]
python step01_downloader.py --start-url https://pytorch.org/docs/stable/ --output pytorch_docs
# Ou plusieurs URLs de d√©part
python step01_downloader.py --start-url https://site1.com/docs --start-url https://site2.com/api --output docs_mixtes

# Option 2: Indexer vos documents locaux (HTML/Markdown/PDF)
python step02_indexer.py docs/ --no-flash-attention

# Lancer en mode local rapide (recommand√©)
python step04_chatbot.py --local-faiss

# Ou lancer en mode public s√©curis√©
python step04_chatbot.py --local-faiss --share
```

### Modes de Lancement

#### Mode Local (D√©faut HuggingFace)
```bash
python step04_chatbot.py
```

#### Mode Local FAISS ‚≠ê **Recommand√©**
```bash
python step04_chatbot.py --local-faiss
```
- üöÄ **5x plus rapide** au d√©marrage
- üîå **Fonctionne offline**
- üìÅ **Utilise directement** vos donn√©es index√©es

#### Mode Public S√©curis√©
```bash
python step04_chatbot.py --local-faiss --share
```
- üåê **Interface publique** accessible via URL Gradio
- üîê **Authentification automatique** (admin / mot_de_passe_16_chars)
- üîë **Nouveau mot de passe** √† chaque d√©marrage

#### Options Avanc√©es
```bash
# Chemin FAISS personnalis√©
python step04_chatbot.py --local-faiss --faiss-path ./mon_index

# Utilisateur admin personnalis√©
python step04_chatbot.py --share --admin-user myuser
```

### Interface Web
1. **Posez votre question** dans le chat
2. **Observez la recherche** en 2 √©tapes (vectorielle ‚Üí reranking)
3. **Lisez la r√©ponse** g√©n√©r√©e en streaming
4. **Consultez les sources** avec scores de pertinence

### Configuration des Mod√®les
- **MPS (Mac)** : Support natif, Flash Attention d√©sactiv√©
- **CUDA (NVIDIA)** : Flash Attention disponible (d√©sactivable)  
- **ZeroGPU** : D√©corateurs `@spaces.GPU` automatiques

### Int√©gration MCP
Connectez votre client MCP pour un acc√®s programmatique :
```python
# Exemple d'utilisation MCP
result = mcp_client.call_tool(
    "ask_rag_question",
    question="Comment impl√©menter des r√©seaux de neurones complexes?",
    num_documents=3,
    use_reranking=True
)
```

## üéØ Cas d'Usage Parfaits

- **Documentation technique**: Recherche dans APIs, guides, tutoriels (HTML/Markdown)
- **Manuels PDF**: Documents techniques, rapports, livres (PDF chunking intelligent)
- **Support client**: R√©ponses bas√©es sur une base de connaissances
- **Recherche acad√©mique**: Analyse de corpus documentaires longs
- **Assistance d√©veloppeur**: Aide contextuelle sur frameworks/librairies
- **Formation**: Syst√®me de questions-r√©ponses intelligent
- **D√©monstrations**: Partage public s√©curis√© d'assistants personnalis√©s

## üìä Performance

- **Recherche**: ~50ms pour 10K+ documents
- **Reranking**: ~200ms pour 20 candidats  
- **G√©n√©ration**: ~2-4s avec streaming
- **M√©moire**: ~6-8GB optimis√© pour ZeroGPU

## üîí S√©curit√© & Confidentialit√©

- **ZeroGPU**: Traitement s√©curis√© sans stockage persistant
- **Donn√©es temporaires**: Pas de r√©tention des questions/r√©ponses
- **Mod√®les locaux**: Traitement dans l'environnement HF Spaces

## üìö Source des Donn√©es

Ce Space utilise des embeddings pr√©-calcul√©s depuis le dataset :
**[VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B](https://huggingface.co/datasets/VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B)**

## üìã TODO / Roadmap

### ‚úÖ Fonctionnalit√©s Compl√®tes
- [x] Pipeline RAG complet (recherche + reranking + g√©n√©ration)
- [x] Interface Gradio avec streaming
- [x] Support multi-plateforme (MPS/CUDA/ZeroGPU)
- [x] **Support PDF avec chunking s√©mantique intelligent**
- [x] **Mode FAISS local (5x plus rapide, offline)**
- [x] **Mode public s√©curis√© avec authentification**
- [x] **Batch processing FAISS (anti-crash)**
- [x] Int√©gration MCP native
- [x] D√©ploiement automatique HuggingFace Spaces

### üîÑ Am√©liorations Futures
- [ ] **Extraction d'images PDF** : Analyse des diagrammes et sch√©mas
- [ ] **OCR pour PDFs scann√©s** : Support des documents num√©ris√©s
- [ ] **Upload documents sources** vers HuggingFace Hub
- [x] **Step01** : T√©l√©chargement automatique de documentation technique depuis internet
- [ ] Support formats additionnels (DOCX, PowerPoint)
- [ ] Interface d'administration pour gestion des documents

---

üöÄ **Projet complet et fonctionnel** - Commencez √† poser vos questions pour d√©couvrir la puissance du RAG avec Qwen3! üîç‚ú®
