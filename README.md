# ğŸ” LocalRAG - SystÃ¨me RAG Local Complet

## Vue d'ensemble

LocalRAG est un systÃ¨me de **Retrieval-Augmented Generation (RAG)** entiÃ¨rement local, conÃ§u pour indexer et interroger efficacement de la documentation technique. Le systÃ¨me fonctionne en plusieurs Ã©tapes orchestrÃ©es pour offrir une recherche sÃ©mantique haute performance sans dÃ©pendance cloud.

## ğŸ—ï¸ Architecture du processus

```mermaid
graph TD
    A[ğŸ“‚ Documentation Source] --> B[Step 01: Indexation]
    B --> C[ğŸ“Š Index Vectoriel FAISS]
    C --> D[Step 02: Upload HF Hub]
    D --> E[ğŸ“¥ SafeTensors + MÃ©tadonnÃ©es]
    E --> F[Step 03: Interface Chat]
    F --> G[ğŸ¯ RÃ©ponse ContextualisÃ©e]
```

## ğŸš€ Installation et prÃ©requis

### PrÃ©requis systÃ¨me
- **GPU requis** : CUDA (NVIDIA) ou MPS (Apple Silicon)
- **Python** : 3.8+
- **RAM** : 8GB minimum, 16GB recommandÃ©
- **Stockage** : 10GB+ selon la taille de la documentation

### Installation
```bash
# Cloner le repository
git clone https://github.com/user/LocalRagModel.git
cd LocalRagModel

# Installer les dÃ©pendances
pip install -r requirements.txt

# VÃ©rifier l'installation GPU
python -c "import torch; print(f'GPU disponible: {torch.cuda.is_available() or torch.backends.mps.is_available()}')"
```

## ğŸ“‹ Ã‰tapes du processus

### âœ… **Step 01 - Indexation** (`step01_indexer.py`)
**Statut**: âœ… ImplÃ©mentÃ© et optimisÃ©

Transforme la documentation brute en index vectoriel searchable.

### âœ… **Step 02 - Upload Embeddings** (`step02_upload_embeddings.py`)  
**Statut**: âœ… ImplÃ©mentÃ©, testÃ© et optimisÃ©

Convertit l'index FAISS en SafeTensors avec structure de mÃ©tadonnÃ©es amÃ©liorÃ©e et upload vers Hugging Face Hub.

### âœ… **Step 03 - Interface Chat** (`step03_chatbot.py`)
**Statut**: âœ… ImplÃ©mentÃ©, optimisÃ© et entiÃ¨rement fonctionnel

Interface de chat Gradio avec streaming utilisant les embeddings de Step 02 et gÃ©nÃ©ration Qwen3-4B-Instruct-2507.

---

## ğŸš€ Step 01 - Indexation Vectorielle

### ğŸ¯ **Objectif**
Convertir la documentation technique (HTML/Markdown) en reprÃ©sentations vectorielles pour permettre une recherche sÃ©mantique ultra-rapide.

### ğŸ“Š **Pipeline de traitement**

```mermaid
graph LR
    A[ğŸ“ Documents] --> B[ğŸ” Parsing]
    B --> C[âœ‚ï¸ Chunking]
    C --> D[ğŸ–¼ï¸ Analyse Images]
    D --> E[ğŸ§  Embeddings]
    E --> F[âš¡ FAISS Index]
```

#### 1. **DÃ©couverte et Parsing** 
- Scan rÃ©cursif des rÃ©pertoires
- Support multi-format : `.html`, `.htm`, `.md`, `.markdown`
- Parser unifiÃ© avec gestion d'erreurs robuste
- Extraction du contenu, titres, sections, images et liens

#### 2. **Segmentation Intelligente**
- DÃ©coupage en chunks sÃ©mantiquement cohÃ©rents
- PrÃ©servation du contexte (titre, section parent)
- Optimisation de la taille pour les modÃ¨les d'embedding

#### 3. **Analyse Multimodale**
- **Images** : Analyse automatique avec Ollama (descriptions contextuelles)
- **Liens** : Extraction et catalogage des rÃ©fÃ©rences
- **MÃ©tadonnÃ©es** : Enrichissement avec informations structurelles

#### 4. **GÃ©nÃ©ration d'Embeddings**
- **ModÃ¨le principal** : `Qwen3-Embedding-4B` (2560 dimensions)
- **Fallback** : `paraphrase-multilingual-MiniLM-L12-v2`
- **Optimisations GPU** : Support MPS (Mac) et CUDA
- **Traitement par batch** adaptatif selon la puissance GPU

#### 5. **Indexation Vectorielle**
- **Backend** : FAISS-HNSW (Facebook AI Similarity Search)
- **Performance** : 10x plus rapide que ChromaDB
- **Persistance** : Sauvegarde automatique sur disque
- **ScalabilitÃ©** : Gestion de millions de vecteurs

### ğŸ› ï¸ **Utilisation**

#### Indexation complÃ¨te
```bash
python step01_indexer.py /path/to/documentation
```

#### Indexation incrÃ©mentale (nouveaux fichiers uniquement)
```bash
python step01_indexer.py /path/to/documentation --incremental
```

#### Test sur un fichier unique
```bash
python step01_indexer.py /path/to/documentation --single-file document.html
```

### âš™ï¸ **Options de configuration**

| Option | Description | RecommandÃ© pour |
|--------|-------------|-----------------|
| `--db-path` | Chemin de l'index FAISS | Personnaliser le stockage |
| `--debug` | Mode debug dÃ©taillÃ© | DÃ©veloppement/Debug |
| `--incremental` | Indexation incrÃ©mentale | Mises Ã  jour rÃ©guliÃ¨res |
| `--no-flash-attention` | DÃ©sactive Flash Attention 2 | Mac avec erreurs GPU |
| `--no-reranker` | DÃ©sactive le reranker | GPU limitÃ© |

### ğŸ“ˆ **Performances**

#### Environnements supportÃ©s
- **ğŸ Mac M1/M2/M3** : MPS (Metal Performance Shaders)
- **ğŸš€ Linux/Windows** : CUDA (NVIDIA GPU)
- **âŒ CPU** : Non supportÃ© (performance insuffisante)

#### MÃ©triques typiques
- **Parsing** : ~100 fichiers HTML/min
- **Embeddings** : ~50 documents/sec (MPS) | ~200 documents/sec (CUDA)
- **Indexation FAISS** : ~1000 vecteurs/sec
- **MÃ©moire** : ~2GB RAM pour 100k chunks

### ğŸ—ƒï¸ **Structure des donnÃ©es**

#### Index FAISS
```
faiss_index/
â”œâ”€â”€ index.faiss          # Index vectoriel HNSW
â”œâ”€â”€ metadata.json        # MÃ©tadonnÃ©es enrichies
â”œâ”€â”€ mappings.pkl         # Mapping ID â†” Index
â””â”€â”€ tracking.json        # Ã‰tat d'indexation
```

#### MÃ©tadonnÃ©es par chunk
```json
{
  "source_file": "/path/to/document.html",
  "title": "Guide d'utilisation",
  "heading": "Configuration avancÃ©e",
  "content_length": 1247,
  "images_count": 3,
  "links_count": 5,
  "indexed_at": "2024-01-15T14:30:00",
  "chunk_content": "Contenu du segment..."
}
```

---

## ğŸŒ Step 02 - Upload Embeddings vers Hugging Face

### ğŸ¯ **Objectif**
Convertir l'index FAISS local en format SafeTensors et l'upload vers Hugging Face Hub pour partage et rÃ©utilisation.

### ğŸ“Š **Pipeline de conversion**

```mermaid
graph LR
    A[ğŸ“‚ Index FAISS] --> B[ğŸ”„ Conversion SafeTensors]
    B --> C[ğŸ“‹ MÃ©tadonnÃ©es JSON]
    C --> D[ğŸ“ README Auto]
    D --> E[ğŸš€ Upload HF Hub]
```

#### 1. **Conversion Format**
- **FAISS â†’ SafeTensors** : Format sÃ©curisÃ© prÃ©fÃ©rÃ© par HF
- **Extraction vecteurs** : Reconstruction depuis index HNSW
- **PrÃ©servation mappings** : ID â†” Index dans mÃ©tadonnÃ©es
- **Validation intÃ©gritÃ©** : VÃ©rification dimensions et cohÃ©rence

#### 2. **Upload SÃ©curisÃ©**
- **Token HF** : Authentification sÃ©curisÃ©e (saisie masquÃ©e)
- **Repository privÃ©/public** : ContrÃ´le de visibilitÃ©
- **MÃ©tadonnÃ©es enrichies** : Documentation complÃ¨te auto-gÃ©nÃ©rÃ©e
- **README automatique** : Guide d'utilisation avec exemples de code

### ğŸ› ï¸ **Utilisation**

#### Upload interactif (recommandÃ©)
```bash
python step02_upload_embeddings.py
```

#### Upload avec paramÃ¨tres
```bash
python step02_upload_embeddings.py --repo-name username/my-embeddings --private
```

#### Test de conversion uniquement
```bash
python step02_upload_embeddings.py --dry-run
```

### âš™ï¸ **Options de configuration**

| Option | Description | Exemple |
|--------|-------------|---------|
| `faiss_index_path` | Chemin index FAISS | `./faiss_index` |
| `--token` | Token HF (ou interactif) | `hf_xxxxx` |
| `--repo-name` | Repository HF | `username/embeddings` |
| `--dataset-name` | Nom du dataset | `embeddings` |
| `--private` | Repository privÃ© | Flag |
| `--dry-run` | Test sans upload | Flag |

### ğŸ“ **Structure uploadÃ©e**

#### Fichiers gÃ©nÃ©rÃ©s sur HF Hub
```
dataset-repo/
â”œâ”€â”€ embeddings.safetensors     # Vecteurs au format SafeTensors
â”œâ”€â”€ embeddings_metadata.json  # MÃ©tadonnÃ©es + mappings ID
â””â”€â”€ README.md                  # Documentation auto-gÃ©nÃ©rÃ©e
```

#### Contenu SafeTensors
```python
{
    'embeddings': torch.Tensor,  # Shape: [n_vectors, dimension]
}
```

#### MÃ©tadonnÃ©es JSON
```json
{
  "format_version": "1.0",
  "total_vectors": 12458,
  "vector_dimension": 2560,
  "faiss_index_type": "HNSW",
  "embedding_model": "Qwen/Qwen3-Embedding-4B",
  "conversion_timestamp": "2024-01-15T14:30:00",
  "ordered_ids": ["doc1#chunk1", "doc1#chunk2", ...],
  "id_to_idx": {"doc1#chunk1": 0, "doc1#chunk2": 1, ...}
}
```

### ğŸ“ˆ **Avantages SafeTensors**

#### vs. Format Pickle (.pkl)
- **âœ… SÃ©curitÃ©** : Pas d'exÃ©cution de code arbitraire
- **âœ… Performance** : Chargement plus rapide
- **âœ… InteropÃ©rabilitÃ©** : Compatible tous frameworks ML
- **âœ… MÃ©tadonnÃ©es** : Format structurÃ© et extensible
- **âœ… Validation** : VÃ©rification intÃ©gritÃ© automatique

#### vs. Index FAISS natif
- **âœ… PortabilitÃ©** : IndÃ©pendant de FAISS
- **âœ… Versioning** : Suivi des versions sur Git LFS
- **âœ… Partage** : Distribution facile via HF Hub
- **âœ… Documentation** : README et mÃ©tadonnÃ©es auto-gÃ©nÃ©rÃ©es

---

## ğŸ¤– Step 03 - Interface RAG avec MCP

### ğŸ¯ **Objectif**
Interface de chat Gradio complÃ¨te avec streaming et serveur MCP intÃ©grÃ© pour l'intÃ©gration directe dans Claude Desktop, VS Code et autres outils compatibles MCP.

### ğŸ—ï¸ **Architecture**

```mermaid
graph LR
    A[ğŸ‘¤ Question] --> B[ğŸ” Recherche Vectorielle]
    B --> C[ğŸ¯ Reranking Qwen3]
    C --> D[ğŸ“š Documents Pertinents]
    D --> E[ğŸ’¬ GÃ©nÃ©ration Qwen3-4B Streaming]
    E --> F[ğŸ¯ RÃ©ponse ContextualisÃ©e]
```

### âš¡ **FonctionnalitÃ©s principales**

#### ğŸ”„ **Chargement automatique depuis HF Hub**
- Lecture automatique de la configuration Step 02
- TÃ©lÃ©chargement des embeddings SafeTensors
- Reconstruction de l'index FAISS pour recherche haute performance

#### ğŸ¯ **Pipeline de recherche en 2 Ã©tapes**
1. **Recherche initiale** : SÃ©lection de 20 candidats par embedding
2. **Reranking** : Affinage avec Qwen3-Reranker-4B pour sÃ©lectionner les documents les plus pertinents

#### ğŸ’¬ **GÃ©nÃ©ration contextuelle avec streaming**
- **ModÃ¨le** : Qwen3-4B-Instruct-2507 (4 milliards de paramÃ¨tres, optimisÃ©)
- **MÃ©thode** : GÃ©nÃ©ration streamÃ©e basÃ©e sur le contexte des documents sÃ©lectionnÃ©s
- **Format** : RÃ©ponses structurÃ©es avec rÃ©fÃ©rences aux sources et scores
- **Streaming** : Affichage progressif token par token pour une expÃ©rience fluide

#### ğŸ”Œ **IntÃ©gration MCP**
- **Fonction exposÃ©e** : `ask_rag_question`
- **ParamÃ¨tres** : question (str), num_documents (1-10), use_reranking (bool)
- **Compatible** : Claude Desktop, VS Code, Cursor IDE
- **Protocol** : Model Control Protocol (MCP) v1.0

#### ğŸ¨ **Interface utilisateur avancÃ©e**
- **Framework** : Gradio avec design moderne
- **Streaming** : Affichage en temps rÃ©el des Ã©tapes de traitement
- **ContrÃ´les** : ParamÃ¨tres ajustables (nombre de documents, activation du reranking)
- **Scores** : Visualisation des scores d'embedding et de reranking

### ğŸ› ï¸ **Utilisation**

#### Mode HTTP (dÃ©veloppement)
```bash
# PrÃ©requis : step03_config.json gÃ©nÃ©rÃ© par Step 02
python step03_chatbot.py
```

#### Mode HTTPS (pour Claude Desktop)
```bash
# GÃ©nÃ©rer certificats SSL
python step03_ssl_generator_optional.py

# Configurer SSL
export SSL_KEYFILE="$(pwd)/ssl_certs/localhost.key"
export SSL_CERTFILE="$(pwd)/ssl_certs/localhost.crt"

# Lancer avec HTTPS + MCP
python step03_chatbot.py
```

**AccÃ¨s :**
- Interface web : `http://localhost:7860` (ou `https://localhost:7860` en SSL)
- Serveur MCP : `http://localhost:7860/gradio_api/mcp/sse`

### ğŸ›ï¸ **ParamÃ¨tres configurables**

| ParamÃ¨tre | Description | Valeur par dÃ©faut |
|-----------|-------------|-------------------|
| **Documents finaux** | Nombre de documents utilisÃ©s pour la gÃ©nÃ©ration | 3 |
| **Reranking** | Activation du reranking Qwen3 | âœ… ActivÃ© |
| **Flash Attention** | AccÃ©lÃ©ration (auto-dÃ©sactivÃ© sur Mac) | Auto-dÃ©tection |

### ğŸ“Š **Performance**

- **Recherche** : ~50ms pour 10k+ documents
- **Reranking** : ~200ms pour 20 candidats
- **GÃ©nÃ©ration** : ~2-4s selon la longueur de rÃ©ponse (streaming)
- **MÃ©moire** : ~6-8GB avec Qwen3-4B (optimisÃ© vs 8B)

### ğŸ”§ **Configuration technique**

#### Plateformes supportÃ©es
- **CUDA** : AccÃ©lÃ©ration GPU complÃ¨te avec Flash Attention
- **MPS (Mac)** : Optimisations spÃ©cifiques pour Apple Silicon
- **CPU** : Fallback automatique avec optimisations
- **ZeroGPU** : Support Hugging Face Spaces avec dÃ©corateurs `@spaces.GPU`

#### ModÃ¨les utilisÃ©s
- **Embeddings** : ChargÃ©s depuis HF Hub (Qwen3-Embedding-4B recommandÃ©)
- **Reranking** : Qwen3-Reranker-4B
- **GÃ©nÃ©ration** : Qwen3-4B-Instruct-2507 via Transformers (compatible MPS)

#### Configuration Claude Desktop
Fichier `~/Library/Application Support/Claude/claude_desktop_config.json` :
```json
{
  "mcpServers": {
    "localrag": {
      "command": "python",
      "args": ["/path/to/LocalRagModel/step03_chatbot.py"],
      "env": {
        "SSL_KEYFILE": "/path/to/ssl_certs/localhost.key",
        "SSL_CERTFILE": "/path/to/ssl_certs/localhost.crt",
        "PYTHONPATH": "/path/to/LocalRagModel"
      }
    }
  }
}
```

---

## ğŸ”§ **Architecture technique**

### Classes principales
- **`TechnicalDocIndexer`** : Orchestrateur principal
- **`UniversalDocumentParser`** : Parser unifiÃ© HTML/Markdown
- **`VectorIndexer`** : Gestionnaire d'embeddings et FAISS
- **`OllamaImageAnalyzer`** : Analyse multimodale des images
- **`Qwen3Reranker`** : Reranking sÃ©mantique

### Flux de donnÃ©es
1. **Fichiers** â†’ **Chunks** (Parser)
2. **Chunks** â†’ **Embeddings** (Qwen3)
3. **Embeddings** â†’ **Index FAISS** (VectorIndexer)
4. **MÃ©tadonnÃ©es** â†’ **JSON** (Tracking)

### âš¡ **Optimisations**

#### Gestion mÃ©moire
- **Nettoyage automatique** : Cache MPS vidÃ© aprÃ¨s chaque batch
- **Batch adaptatif** : Taille ajustÃ©e selon GPU et longueur documents
- **Streaming** : Traitement par petits lots pour Ã©viter l'OOM

#### Performance GPU
- **Pas de fallback CPU** : Ã‰chec immÃ©diat si GPU indisponible
- **Flash Attention 2** : AccÃ©lÃ©ration des transformers (CUDA)
- **Precision mixte** : FP16 automatique sur GPU compatibles

### ğŸš¨ **Gestion d'erreurs**

#### Robustesse
- **Collecteur d'erreurs** : Catalogage centralisÃ© des Ã©checs
- **Continuation** : Traitement des autres fichiers si un Ã©choue
- **Rapport dÃ©taillÃ©** : Statistiques complÃ¨tes en fin d'exÃ©cution

#### Types d'erreurs gÃ©rÃ©es
- Images manquantes ou corrompues
- HTML malformÃ©
- Timeouts GPU
- Erreurs d'encoding

---

## ğŸ†• **AmÃ©liorations rÃ©centes**

### âœ… **Corrections majeures (v1.1)**
- **ğŸ”§ Reranking fonctionnel** : Correction du mapping mÃ©tadonnÃ©es qui causait des scores uniformes
- **ğŸ“Š Validation d'intÃ©gritÃ©** : Nouveau systÃ¨me de validation automatique du mapping index â†” mÃ©tadonnÃ©es
- **ğŸ—ï¸ Structure mÃ©tadonnÃ©es optimisÃ©e** : SÃ©paration claire entre mÃ©tadonnÃ©es techniques et de contenu
- **ğŸ”„ Streaming implÃ©mentÃ©** : GÃ©nÃ©ration de rÃ©ponse progressive token par token
- **âš¡ ModÃ¨le optimisÃ©** : Migration vers Qwen3-4B-Instruct-2507 (plus lÃ©ger, compatible MPS)
- **ğŸ› ï¸ Gestion d'erreurs robuste** : Upload avec reporting dÃ©taillÃ© des Ã©checs

### ğŸ¯ **RÃ©sultats**
- **Reranking** : Scores variables et pertinents (fini les 0.091 uniformes)
- **Performance** : -25% mÃ©moire avec Qwen3-4B vs 8B
- **UX** : RÃ©ponses streamÃ©es pour une expÃ©rience fluide
- **FiabilitÃ©** : Validation automatique dÃ©tecte les problÃ¨mes de mapping

---

## ğŸ“… **Roadmap**

### ğŸ”§ **Step 04 - API REST** (Ã€ implÃ©menter)
- API FastAPI pour intÃ©gration
- Endpoints de recherche et gÃ©nÃ©ration  
- Authentification et rate limiting
- Documentation OpenAPI

### ğŸŒ **Step 05 - DÃ©ploiement** (Ã€ implÃ©menter)
- Conteneurisation Docker
- Orchestration Kubernetes
- Monitoring et observabilitÃ©
- ScalabilitÃ© horizontale

---

## ğŸ›¡ï¸ **SÃ©curitÃ© et confidentialitÃ©**

- **100% Local** : Aucune donnÃ©e envoyÃ©e vers des services externes
- **Chiffrement** : Index FAISS peut Ãªtre chiffrÃ© au repos
- **Isolation** : Traitement en sandbox local
- **ContrÃ´le total** : Vos donnÃ©es restent sur votre infrastructure

---

## ğŸ“Š **Statistiques d'utilisation**

AprÃ¨s indexation, le script affiche :
- Nombre de fichiers traitÃ©s
- Chunks gÃ©nÃ©rÃ©s et indexÃ©s
- Images analysÃ©es
- Erreurs rencontrÃ©es
- Temps de traitement total
- Taille de l'index final

**Exemple** :
```
âœ… Indexation terminÃ©e !
ğŸ“Š Statistiques finales :
   - Fichiers traitÃ©s : 1,247
   - Chunks gÃ©nÃ©rÃ©s : 12,458  
   - Images analysÃ©es : 3,891
   - Vecteurs indexÃ©s : 12,458
   - Erreurs : 23 (1.8%)
   - DurÃ©e totale : 4min 32s
   - Index FAISS : 2.1 GB
```

---

## ğŸ¤ **Contribution**

Le projet suit une architecture modulaire permettant des contributions ciblÃ©es :
- **Step 01** : Optimisations d'indexation
- **Step 02+** : Nouvelles Ã©tapes du pipeline
- **Parsers** : Support de nouveaux formats
- **Backends** : IntÃ©gration d'autres bases vectorielles