---
title: Swift MLX documentation research
emoji: üîç
colorFrom: blue
colorTo: green
sdk: gradio
sdk_version: 5.43.1
app_file: step03_chatbot.py
pinned: false
license: mit
hardware: zerogpu
short_description: Search in the Swift MLX documentation
models:
- Qwen/Qwen3-Embedding-4B
- Qwen/Qwen3-Reranker-4B
- Qwen/Qwen3-4B-Instruct-2507
datasets:
- VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B
tags:
- rag
- retrieval-augmented-generation
- qwen3
- semantic-search
- question-answering
- zero-gpu
- mcp-server
- faiss
---

# üîç LocalRAG - Syst√®me RAG Complet avec Qwen3

‚úÖ **Syst√®me complet et fonctionnel** - Compatible MPS (Mac), CUDA et ZeroGPU Spaces

Syst√®me RAG (Retrieval-Augmented Generation) utilisant les mod√®les Qwen3 de derni√®re g√©n√©ration avec pipeline 2 √©tapes : recherche vectorielle + reranking + g√©n√©ration stream√©e.

## ‚ö° Fonctionnalit√©s

### üß† **Mod√®les IA Avanc√©s**
- **Embeddings**: Qwen3-Embedding-4B (2560 dimensions)
- **Reranking**: Qwen3-Reranker-4B pour l'affinage des r√©sultats
- **G√©n√©ration**: Qwen3-4B-Instruct-2507 avec streaming
- **Optimisation ZeroGPU**: Support natif avec d√©corateurs @spaces.GPU

### üìÑ **Support Multi-Formats avec PDF Intelligent**
- **HTML/Markdown**: Parsing structurel avec pr√©servation hi√©rarchique
- **PDF avanc√©**: Chunking s√©mantique intelligent pour documents longs (50+ pages)
- **D√©tection automatique**: Structure, TOC et titres des PDFs
- **Overlap contextuel**: Pr√©servation du contexte entre chunks (100-200 mots)
- **Batch processing**: Indexation par lots pour √©viter les crashes m√©moire

### üîç **Recherche S√©mantique Avanc√©e**
- **Pipeline 2 √©tapes**: Recherche vectorielle + reranking
- **Index FAISS**: Recherche haute performance sur de gros volumes
- **Scores d√©taill√©s**: Embedding + reranking pour chaque document
- **S√©lection intelligente**: Top-K adaptatif selon pertinence

### üöÄ **Modes de D√©ploiement Flexibles**
- **Mode HuggingFace Hub**: T√©l√©chargement automatique des embeddings
- **Mode FAISS Local**: Utilisation directe de l'index local (5x plus rapide)
- **Mode Offline**: Fonctionnement complet sans connexion internet
- **Mode Public S√©curis√©**: Partage via URL avec authentification admin

### üîê **S√©curit√© et Authentification**
- **Mot de passe al√©atoire**: 16 caract√®res cryptographiquement s√©curis√©s
- **G√©n√©ration automatique**: Combinaison lettres + chiffres + symboles
- **Session unique**: Nouveau mot de passe √† chaque d√©marrage
- **Contr√¥le d'acc√®s**: Interface publique avec protection admin

### üí¨ **G√©n√©ration Contextuelle**
- **Streaming**: R√©ponse progressive token par token
- **Contexte enrichi**: Int√©gration des documents les plus pertinents
- **R√©f√©rences**: Sources avec scores de pertinence
- **Qualit√©**: R√©ponses bas√©es uniquement sur le contexte fourni

### üîå **Int√©gration MCP**
- **Serveur MCP natif**: Fonction `ask_rag_question()` expos√©e
- **Param√®tres configurables**: Nombre documents, activation reranking
- **Compatible**: Claude Desktop, VS Code, Cursor IDE
- **API structur√©e**: R√©ponses JSON avec sources et m√©tadonn√©es

## üõ†Ô∏è Architecture & √âtapes

### Pipeline de Traitement
1. **Step01** : Indexation universelle (HTML/Markdown/PDF ‚Üí FAISS + m√©tadonn√©es)
2. **Step02** : Upload embeddings vers HuggingFace Hub (optionnel)
3. **Step03** : Interface de chat RAG (mode local ou cloud)
4. **Step04** : D√©ploiement automatique sur HuggingFace Spaces

### Recherche en 2 √âtapes
1. **Recherche vectorielle** : FAISS IndexFlatIP (cosine similarity)
2. **Reranking** : Qwen3-Reranker-4B pour affiner la pertinence
3. **G√©n√©ration** : Qwen3-4B-Instruct-2507 avec streaming

## üöÄ Utilisation

### Installation & D√©marrage Rapide
```bash
# Cloner le projet
git clone [repo-url]
cd LocalRagModel

# Installer les d√©pendances (inclut PyMuPDF pour PDF)
pip install -r requirements.txt

# Indexer vos documents (HTML/Markdown/PDF)
python step01_indexer.py docs/ --no-flash-attention

# Lancer en mode local rapide (recommand√©)
python step03_chatbot.py --local-faiss

# Ou lancer en mode public s√©curis√©
python step03_chatbot.py --local-faiss --share
```

### Modes de Lancement

#### Mode Local (D√©faut HuggingFace)
```bash
python step03_chatbot.py
```

#### Mode Local FAISS ‚≠ê **Recommand√©**
```bash
python step03_chatbot.py --local-faiss
```
- üöÄ **5x plus rapide** au d√©marrage
- üîå **Fonctionne offline**
- üìÅ **Utilise directement** vos donn√©es index√©es

#### Mode Public S√©curis√©
```bash
python step03_chatbot.py --local-faiss --share
```
- üåê **Interface publique** accessible via URL Gradio
- üîê **Authentification automatique** (admin / mot_de_passe_16_chars)
- üîë **Nouveau mot de passe** √† chaque d√©marrage

#### Options Avanc√©es
```bash
# Chemin FAISS personnalis√©
python step03_chatbot.py --local-faiss --faiss-path ./mon_index

# Utilisateur admin personnalis√©
python step03_chatbot.py --share --admin-user myuser
```

### Interface Web
1. **Posez votre question** dans le chat
2. **Observez la recherche** en 2 √©tapes (vectorielle ‚Üí reranking)
3. **Lisez la r√©ponse** g√©n√©r√©e en streaming
4. **Consultez les sources** avec scores de pertinence

### Configuration des Mod√®les
- **MPS (Mac)** : Support natif, Flash Attention d√©sactiv√©
- **CUDA (NVIDIA)** : Flash Attention disponible (d√©sactivable)  
- **ZeroGPU** : D√©corateurs `@spaces.GPU` automatiques

### Int√©gration MCP
Connectez votre client MCP pour un acc√®s programmatique :
```python
# Exemple d'utilisation MCP
result = mcp_client.call_tool(
    "ask_rag_question",
    question="Comment impl√©menter des r√©seaux de neurones complexes?",
    num_documents=3,
    use_reranking=True
)
```

## üéØ Cas d'Usage Parfaits

- **Documentation technique**: Recherche dans APIs, guides, tutoriels (HTML/Markdown)
- **Manuels PDF**: Documents techniques, rapports, livres (PDF chunking intelligent)
- **Support client**: R√©ponses bas√©es sur une base de connaissances
- **Recherche acad√©mique**: Analyse de corpus documentaires longs
- **Assistance d√©veloppeur**: Aide contextuelle sur frameworks/librairies
- **Formation**: Syst√®me de questions-r√©ponses intelligent
- **D√©monstrations**: Partage public s√©curis√© d'assistants personnalis√©s

## üìä Performance

- **Recherche**: ~50ms pour 10K+ documents
- **Reranking**: ~200ms pour 20 candidats  
- **G√©n√©ration**: ~2-4s avec streaming
- **M√©moire**: ~6-8GB optimis√© pour ZeroGPU

## üîí S√©curit√© & Confidentialit√©

- **ZeroGPU**: Traitement s√©curis√© sans stockage persistant
- **Donn√©es temporaires**: Pas de r√©tention des questions/r√©ponses
- **Mod√®les locaux**: Traitement dans l'environnement HF Spaces

## üìö Source des Donn√©es

Ce Space utilise des embeddings pr√©-calcul√©s depuis le dataset :
**[VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B](https://huggingface.co/datasets/VincentGOURBIN/swift-mlx-Qwen3-Embedding-4B)**

## üìã TODO / Roadmap

### ‚úÖ Fonctionnalit√©s Compl√®tes
- [x] Pipeline RAG complet (recherche + reranking + g√©n√©ration)
- [x] Interface Gradio avec streaming
- [x] Support multi-plateforme (MPS/CUDA/ZeroGPU)
- [x] **Support PDF avec chunking s√©mantique intelligent**
- [x] **Mode FAISS local (5x plus rapide, offline)**
- [x] **Mode public s√©curis√© avec authentification**
- [x] **Batch processing FAISS (anti-crash)**
- [x] Int√©gration MCP native
- [x] D√©ploiement automatique HuggingFace Spaces

### üîÑ Am√©liorations Futures
- [ ] **Extraction d'images PDF** : Analyse des diagrammes et sch√©mas
- [ ] **OCR pour PDFs scann√©s** : Support des documents num√©ris√©s
- [ ] **Upload documents sources** vers HuggingFace Hub
- [ ] **Step00** : T√©l√©chargement automatique de documentation technique depuis internet
- [ ] Support formats additionnels (DOCX, PowerPoint)
- [ ] Interface d'administration pour gestion des documents

---

üöÄ **Projet complet et fonctionnel** - Commencez √† poser vos questions pour d√©couvrir la puissance du RAG avec Qwen3! üîç‚ú®
